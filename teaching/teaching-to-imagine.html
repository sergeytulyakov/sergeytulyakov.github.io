<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <title>Teaching Computers to Imagine with Deep Generative Models</title>
    <!-- Bootstrap Core CSS -->
    <link href="../css/bootstrap.min.css" rel="stylesheet"/>
    <link href="../css/bootstrap-social.css" rel="stylesheet"/>
    <link href="../css/custom.css" rel="stylesheet"/>
    <!-- Custom CSS -->
    <link href="../css/modern-business.css" rel="stylesheet"/>
    <!-- Custom Fonts -->
    <link href="../font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>

    <script src="../js/jquery.js"></script>
    <script src="../js/bootstrap.min.js"></script>
</head>
<body>

<!-- Page Content -->
<div class="container">
    <!-- Marketing Icons Section -->
    <div class="row">
        <h1 class="text-center">Teaching Computers to Imagine with Deep Generative Models</h1>
        <h3 class="text-center">Sergey Tulyakov, Stéphane Lathuilière</h3>
        <h3 class="text-center"> November 19 - 26, 2019 </h3>
        <h3 class="text-center"> The University of Trento, Italy </h3>
        <h2 class="text-center">Abstract</h2>

        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            Recent methods in computer vision can be roughly categorized as those that provide some decision given an
            input image or a video. Such decision includes the number of objects in the input, their type (ie car, tree,
            etc). In other words, they provide some sort of labelling capabilities. We term such methods as
            discriminative. Another group of methods, termed generative models, models the distribution of inputs. Such
            techniques offer generative capabilities, given some input such methods can generate an image, video, audio
            or text. Moreover, these methods can be conditioned on user input offering some sort of control on what is
            being generated. This control includes changing a particular attribute of an image, while keeping other
            attributes unchanged, such as summer to winter, male to female, smiling to non-smiling face. For humans,
            changing an attribute requires careful training, specialized software and is time consuming. Therefore, such
            capabilities can be considered as a form of learned imagination. Do to the ability to “imagine” generative
            techniques have been widely used in a variety of applications: image synthesis, style transfer,
            image-to-image translation, video synthesis and retargeting. Such models are used to enhance discriminative
            techniques with unlabelled or synthetic data, learn to reconstruct 3D when 3D labels are not available.
        </div>

        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            <br/><b>Focus:</b> generative models in deep learning and their applications to image and video
            manipulation, translation as well as methods capitalizing upon such models to perform discriminative tasks.
        </div>
        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            <br/><b>Prerequisites:</b> this course requires an understanding of the basic building blocks of
            convolutional
            neural networks and machine learning theory, including standard deep learning architectures, cost functions,
            activations and learning paradigms. Therefore, for PhD students that have not already worked on deep neural
            networks an introductory course such as <a href="https://ict.unitn.it/node/499">Introduction to Deep
            Learning</a> or <a href="https://ict.unitn.it/node/493">Deep Learning for Image Processing</a> is highly
            recommended.
        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            <h2 class="page-header">Instructors</h2>
            <div class="col-lg-3 col-md-3 col-sm-3">
                <img src="http://www.stulyakov.com/images/sergey.jpg" class="img-responsive img-rounded center-block"/>
                <p class="text-center"><a href="http://www.stulyakov.com">Sergey Tulyakov</a></p>
            </div>
            <div class="col-lg-3 col-md-3 col-sm-3">
                <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=xllguWMAAAAJ&citpid=4"
                     class="img-responsive img-rounded center-block"/>
                <p class="text-center"><a href="https://stelat.eu/">Stéphane Lathuilière</a></p>
            </div>
        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            <h2 class="page-header">Program</h2>
        </div>

        <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
            <table class="table">
            	<tr>
            		<td colspan="3"><h4 class="text-center">November 19</h4></td>
        		</tr>
                <tr>
                    <th class="col-md-2" scope="row" rowspan="2">9:30-11:30</th>
                    <td>Introduction to the course. Introduction to Deep Learning</td>
                    <td><a href="https://docs.google.com/presentation/d/10-fLGzMaAtWxWkQ9aUZFNjvm9IKnMKBALXl1M5PklmM/edit#slide=id.g6b4f31b092_1_12">Slides</a><br/>
                </tr>
                <tr>
                    <td>Generative Adversarial Networks</td>
                    <td><a href="https://docs.google.com/presentation/d/1FmaDYPB8ybLtSi8lii10TQSL9aQIOWn4JK4bgqzv2B4/edit">Slides</a></td>
                </tr>
                <tr>
                    <th class="col-md-2" scope="row">14:00-16:00</th>
                    <td>Variational Autoencoders</td>
                    <td><a href="vae.pdf">Slides</a><br/>
                    	<a href="vae-derivations.pdf">Derivations</a>
                    <a href="https://docs.google.com/document/d/15U_RjRlCaNc8kckT-8FkOBcWrklMmsZyz3s6HIEX2nE/edit?usp=sharing">References</a></td>
                </tr>
                <tr>
            		<td colspan="3"><h4 class="text-center">November 20</h4></td>
        		</tr>
        		<tr>
                    <th class="col-md-2" scope="row">10:00-12:00</th>
                    <td>Generative adversarial networks continued. Image-to-image translation</td>
                    <td ><a href="image-to-image.pdf">Slides</a></td>
                </tr>
                <tr>
                    <th class="col-md-2" scope="row">14:00-16:00</th>
                    <td>Practical session on GANs</td>
                    <td><a href="https://colab.research.google.com/drive/10MYTe67h9WrdBu_HLlJJUY5a3sChFQXb?authuser=1&usp=drive_open">Colab</td>
                </tr>
                <tr>
            		<td colspan="3"><h4 class="text-center">November 21</h4></td>
        		</tr>
                <tr>
                    <th class="col-md-2" scope="row" rowspan="3">10:00-12:00</th>
                    <td>Pose-guided generation</td>
                    <td><a href="https://docs.google.com/presentation/d/1-F4wnKM1X3HdkV82Sifhba9dI9PfGTusATaBs6bOvuU/edit">Slides</a></td>
                </tr>
                <tr>
                    <td>Video synthesis: generation, prediction, translation, retargeting</td>
                    <td><a href="video-synthesis.pdf">Slides</a></td>
                </tr>
                <tr>
                    <td>Gradient-based style-transfer and adversarial examples</td>
                    <td><a href="https://docs.google.com/presentation/d/1WeKbXXhiIgOCBoHW70x7vQdahssCPKlyYLLWv0vwY88/edit#slide=id.g621fcc69eb_0_151">Slides</a></td>
                </tr>
                <tr>
                    <th class="col-md-2" scope="row">14:00-16:00</th>
                    <td>Practical session on VAEs</td>
                    <td><a href="https://colab.research.google.com/drive/1QKuyj9npm_ss87mneX6_fc-ftpulPF2S">Colab</td>
                </tr>
                <tr>
            		<td colspan="3"><h4 class="text-center">November 22</h4></td>
        		</tr>
                <tr>
                    <th class="col-md-2" scope="row" rowspan="3">10:00-12:00</th>
                    <td>Deep Fakes</td>
                    <td><a href="deep-fakes.pdf">Slides</a></td>
                </tr>
                <tr>
                	<td>Improving discriminative models</td>
                    <td><a href="improving-discriminative.pdf">Slides</a></td>
                </tr>
                <tr>
                    <td>Challenge: extending MoCoGAN</td>
                    <td><a href="challenge.pdf">Slides</a><br/>
                    <a href="https://colab.research.google.com/drive/1H59P2LNZPM5pRgjiMPgrjGCDTasv60p5">Colab</a></td>
                </tr>
            </table>                     
    </div>
    <footer>
        <div class="row">
            <div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
				<hr>
                <p>November 2019</p>
            </div>
        </div>
    </footer>


</div>

</body>
</html>

<!doctype html>
<html lang="en" data-bs-theme="auto">

<head>

  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QNDF56NXQS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QNDF56NXQS');
</script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Sergey Tulyakov</title>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/font-awesome.min.css">
  <link href="assets/dist/css/bootstrap.min.css" rel="stylesheet">

  <style>
    .testimonial-group>.row {
      overflow-x: auto;
      white-space: nowrap;
    }

    .testimonial-group>.row>.col-xs-4 {
      display: inline-block;
      float: none;
    }

    /* Style all font awesome icons */
    .fa {
      padding: 10px;
      font-size: 20px !important;
      width: 40px;
      height: 40px;
      text-align: center;
      text-decoration: none;
      border-radius: 50%;
    }

    .fa-img {
      width: 40px;
      height: 40px;
      border-radius: 50%;
    }

    /* Add a hover effect if you want */
    .fa:hover {
      opacity: 0.7;
    }

    /* Set a specific color for each brand */

    /* Facebook */
    .fa-facebook {
      background: #3B5998;
      color: white;
    }

    .fa-snapchat {
      background: #FFFC00;
      color: black;
    }

    /* Twitter */
    .fa-twitter {
      background: #55ACEE;
      color: white;
    }

    /* Twitter */
    .fa-linkedin {
      background: #007bb5;
      color: white;
    }

    .fa-github {
      background: #444444;
      color: white;
    }

    .fa-x-twitter {
      background: #000000;
      color: white;
    }

    .fa-google-scholar {
      background: #316CF4;
      color: white;
    }

    .fa-envelope {
      background: #316CF4;
      color: white;
    }

    .bd-placeholder-img {
      font-size: 1.125rem;
      text-anchor: middle;
      -webkit-user-select: none;
      -moz-user-select: none;
      user-select: none;
    }

    @media (min-width: 768px) {
      .bd-placeholder-img-lg {
        font-size: 3.5rem;
      }
    }

    .nav-scroller {
      position: relative;
      z-index: 2;
      height: 2.75rem;
      overflow-y: hidden;
    }

    .nav-scroller .nav {
      display: flex;
      flex-wrap: nowrap;
      padding-bottom: 1rem;
      margin-top: -1px;
      overflow-x: auto;
      text-align: center;
      white-space: nowrap;
      -webkit-overflow-scrolling: touch;
    }

    /* timeline */

    body {
      margin-top: 20px;
    }

    .timeline-steps {
      display: inline-flex;
      justify-content: center;
      flex-wrap: nowrap
    }

    .timeline-steps .timeline-step {
      align-items: center;
      display: flex;
      flex-direction: column;
      position: relative;
      margin: 1rem
    }

    @media (min-width:768px) {
      .timeline-steps .timeline-step:not(:last-child):after {
        content: "";
        display: block;
        border-top: .25rem dotted #3b82f6;
        width: 3.46rem;
        position: absolute;
        left: 7.5rem;
        top: .3125rem
      }

      .timeline-steps .timeline-step:not(:first-child):before {
        content: "";
        display: block;
        border-top: .25rem dotted #3b82f6;
        width: 3.8125rem;
        position: absolute;
        right: 7.5rem;
        top: .3125rem
      }
    }

    .timeline-steps .timeline-content {
      width: 10rem;
      text-align: center
    }

    .timeline-steps .timeline-content .inner-circle {
      border-radius: 1.5rem;
      height: 1rem;
      width: 1rem;
      display: inline-flex;
      align-items: center;
      justify-content: center;
    }

    .notify-badge {
      position: absolute;
      top: 3%;
      left: 3%;
    }

    .item {
      position: relative;
      display: inline-block;
    }

    .scrolling-wrapper {
      overflow-x: auto;
    }

    .social {
      text-decoration: none !important;
    }

    .last {
      scroll-snap-align: end;
    }

    .img-max {
      max-width: 380px;
      width:100%;
    }
  </style>

  <script>
    window.onload = function () {
      var scrollContainer = document.getElementById('scroll-container');
      scrollContainer.scrollLeft = scrollContainer.scrollWidth;
    }
  </script>

</head>

<body>

  <div class="my-3 py-3 text-center">
    <img class="d-block mx-auto mb-4 rounded-circle" src="images/sergey-2021.jpg" alt="" width="256" height="256">
    <h2 class="display-5 fw-bold text-body-emphasis">Sergey Tulyakov</h2>
    <div class="col-lg-6 col-sm-11 col-xs-11 mx-auto">
      <p class="lead mb-4">Welcome! I'm a Director of Research, leading the Creative Vision at Snap Inc. We build large
        generative models, make them efficient, and personalized.</p>
      <div class="gap-2 d-sm-flex justify-content-sm-center">
        <a href="https://twitter.com/SergeyTulyakov" class="social">
          <i class="fa fa-brands fa-x-twitter"></i>
        </a>
        <a href="https://www.linkedin.com/in/sergeytulyakov/" class="social">
          <i class="fa fa-brands fa-linkedin"></i>
        </a>
        <a href="https://www.facebook.com/s.tulyakov" class="social">
          <i class="fa fa-brands fa-facebook"></i>
        </a>
        <a href="https://github.com/sergeytulyakov" class="social">
          <i class="fa fa-brands fa-github"></i>
        </a>
        <a href="https://scholar.google.com/citations?user=mgzXR0sAAAAJ" class="social">
          <i class="fa fa-brands fa-google-scholar"></i>
        </a>
        <a href="mailto:stulyakov@snap.com" class="social">
          <i class="fa fa-envelope"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="py-3 text-left col-lg-8 col-sm-11 col-xs-11 mx-auto">
    <h3 class="display-6 fw-bold">Research</h3>
    <p class="lead mb-4">At Creative Vision, we strive to transform anyone into a creator. To achieve this, we focus on three core elements: skill, efficiency, and personalization. Our <em>large generative models</em> for images, videos, 3D, and 4D significantly boost skill. But that’s not enough! The creative process demands instantaneous feedback. To do so, we push <em>efficiency</em> to the edge, enabling our models to run on mobile phones at nearly real-time speeds while utilizing only a fraction of the size of larger models. Yet, this is still not enough. Each creator possesses a unique style and <em>personality</em>. Therefore, we not only build models that are efficient, but also make them personalized. Since the inception of our team, we have contributed substantially to products, used by hundreds of millions of Snapchatters everyday!
</p>
    <p class="lead mb-4">If our mission resonates with you, please send us an email. We are constantly in search of interns, collaborators, and researchers.
</p>
  </div>

  <div class="text-left col-lg-8 col-sm-11 col-xs-11 mx-auto">
    <h3 class="display-6 fw-bold">Experience</h3>
    <div class="container col-lg-12">

      <div id="scroll-container" class="row scrolling-wrapper flex-row flex-nowrap mt-4 pb-4 pt-2">
        <div class="col">
          <div class="timeline-steps">

            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/bsuir.png ">
                </div>
                <p class="h6 mt-3 mb-1">2009</p>
                <p class="h6 text-muted mb-0 mb-lg-0">B.Eng at Belorusian State University of Informatics and Radioelectronics</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/bsuir.png ">
                </div>
                <p class="h6 mt-3 mb-1">2010</p>
                <p class="h6 text-muted mb-0 mb-lg-0">MSC at Belorusian State University of Informatics and Radioelectronics</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/unitn.png ">
                </div>
                <p class="h6 mt-3 mb-1">2012-2017</p>
                <p class="h6 text-muted mb-0 mb-lg-0">PhD at University of Trento, Italy</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/cmu.png ">
                </div>
                <p class="h6 mt-3 mb-1">Sept 2010 - Feb 2015</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Research intern at the Robotics Institute, Carnegie-Mellon University</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/msft.png ">
                </div>
                <p class="h6 mt-3 mb-1">Aug 2016 - Nov 2016</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Research Intern at Microsoft Research, Cambridge, UK</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/nvidia.png ">
                </div>
                <p class="h6 mt-3 mb-1">Jan 2017 - Apr 2017</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Research Intern at NVIDIA Research, Santa Clara, CA</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/snap.png ">
                </div>
                <p class="h6 mt-3 mb-1">Jul 2017</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Joined Snap Inc. as Senior Research Scientist</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/snap.png ">
                </div>
                <p class="h6 mt-3 mb-1">Dec 2018</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Lead Research Scientist</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/snap.png ">
                </div>
                <p class="h6 mt-3 mb-1">Mar 2021</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Principal Research Scientist, Manager</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/snap.png ">
                </div>
                <p class="h6 mt-3 mb-1">Mar 2022</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Principal Research Scientist, Senior Manager</p>
              </div>
            </div>
            
            <div class="timeline-step">
              <div class="timeline-content">
                <div class="inner-circle">
                  <img class="fa-img" src=" images/snap.png ">
                </div>
                <p class="h6 mt-3 mb-1">Jul 2024</p>
                <p class="h6 text-muted mb-0 mb-lg-0">Director of Research</p>
              </div>
            </div>
            
            
          </div>
        </div>
      </div>
    </div>

  </div>

  <div class="py-3 text-left col-lg-8 col-sm-11 col-xs-11 mx-auto">
    <h3 class="display-6 fw-bold">Community Service</h3>

    <p class="lead mb-4">I served as a technical program comitte member for all major computer vision, graphics and
      machine learning conferences: CVPR, ECCV, ICCV, NeurIPS, ICLR, SIGGRAPH, SIGGRAPH Asia, ICML. Since 2022 I serve
      as an AC for CVPR, ICML, NeurIPS, ICLR, WACV, 3DV, ECCV, ICCV. Since June 2024 I&apos;m serving as an
      Associate Editor for TPAMI.</p>

    <p class="lead mb-4">Our team organizes tutorials, teaches courses, and gives keynotes.</p>

    <div class="album py-5">
      <div class="container">

        <div class="row row-cols-1 row-cols-sm-2 row-cols-md-2 g-3">

          <div class="col">
            <div class="card shadow-sm">
              <div class="card-body">
                <p class="card-text">A week-long course on "Teaching Computers to Imagine with Deep Generative Models"
                </p>
                <div class="d-flex justify-content-between align-items-center">
                  <div class="btn-group">
                    <a href="https://stulyakov.com/teaching/teaching-to-imagine.html" type="button"
                    class="btn btn-primary btn-sm">Materials</a>
                  </div>
                  <small class="text-body-secondary">Universty of Trento'2019</small>
                </div>
              </div>
            </div>
          </div>

          <div class="col">
            <div class="card shadow-sm">
              <div class="card-body">
                <p class="card-text">A tutorial on "Unlocking Creativity with Computer Vision: Representations for
                  Animation, Stylization and Manipulation"</p>
                <div class="d-flex justify-content-between align-items-center">
                  <div class="btn-group">
                    <a href="https://snap-research.github.io/representations-for-creativity" type="button"
                    class="btn btn-primary btn-sm">Materials</a>
                  </div>
                  <small class="text-body-secondary">CVPR'2020</small>
                </div>
              </div>
            </div>
          </div>

          <div class="col">
            <div class="card shadow-sm">
              <div class="card-body">
                <p class="card-text">A tutorial on "Video Synthesis: Early Days and New Developments"</p>
                <div class="d-flex justify-content-between align-items-center">
                  <div class="btn-group">
                    <a href="https://snap-research.github.io/video-synthesis-tutorial" type="button"
                    class="btn btn-primary btn-sm">Materials</a>
                  </div>
                  <small class="text-body-secondary">ECCV'2022</small>
                </div>
              </div>
            </div>
          </div>

          <div class="col">
            <div class="card shadow-sm">
              <div class="card-body">
                <p class="card-text">A tutorial on "Efficient Neural Networks: From Algorithm Design to Practical Mobile
                  Deployments"</p>
                <div class="d-flex justify-content-between align-items-center">
                  <div class="btn-group">
                    <a href="https://snap-research.github.io/efficient-nn-tutorial" type="button"
                    class="btn btn-primary btn-sm">Materials</a>
                  </div>
                  <small class="text-body-secondary">CVPR'2023</small>
                </div>
              </div>
            </div>
          </div>

        </div>
      </div>
    </div>

  </div>

  <div class="py-3 text-left col-lg-8 col-sm-11 mx-auto">
    <h3 class="display-6 fw-bold">Publications</h3>

    <p class="lead py-3">This is an incomplete list. Please see my <a href="https://scholar.google.com/citations?user=mgzXR0sAAAAJ">google scholar.</a></p>

    <div class="container">

      <div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/sf-v-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>SF-V: Single Forward Video Generation Model</strong>
     
            <p>
              Zhixing Zhang, Yanyu Li, Yushu Wu, Yanwu Xu, Anil Kag, Ivan Skorokhodov, Willi Menapace, Aliaksandr Siarohin, Junli Cao, Dimitris Metaxas, Sergey Tulyakov, Jian Ren
            </p>

            

            <a href="https://snap-research.github.io/SF-V/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.04324" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <img src="publications/images/bitsfusion.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>BitsFusion: 1.99 bits Weight Quantization of Diffusion Model</strong>
     
            <p>
              Yang Sui, Yanyu Li, Anil Kag, Yerlan Idelbayev, Junli Cao, Ju Hu, Dhritiman Sagar, Bo Yuan, Sergey Tulyakov, Jian Ren
            </p>

            

            <a href="https://snap-research.github.io/BitsFusion/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.04333" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <img src="publications/images/lightweight-gs.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Lightweight Predictive 3D Gaussian Splats</strong>
     
            <p>
              Junli Cao, Vidit Goel, Chaoyang Wang, Anil Kag, Ju Hu, Sergei Korolev, Chenfanfu Jiang, Sergey Tulyakov, Jian Ren
            </p>

            

            <a href="https://plumpuddings.github.io/LPGS/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.19434" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/genau.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Taming Data and Transformers for Audio Generation</strong>
     
            <p>
              Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, Vicente Ordonez
            </p>

            

            <a href="https://snap-research.github.io/GenAU/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.19388" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/4real.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models</strong>
     
            <p>
              Heng Yu, Chaoyang Wang, Peiye Zhuang, Willi Menapace, Aliaksandr Siarohin, Junli Cao, Laszlo A Jeni, Sergey Tulyakov, Hsin-Ying Lee
            </p>

            

            <a href="https://snap-research.github.io/4Real/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.07472" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/gtr.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>GTR: Improving Large 3D Reconstruction Models through Geometry and Texture Refinement</strong>
     
            <p>
              Peiye Zhuang, Songfang Han, Chaoyang Wang, Aliaksandr Siarohin, Jiaxu Zou, Michael Vasilkovsky, Vladislav Shakhrai, Sergey Korolev, Sergey Tulyakov, Hsin-Ying Lee
            </p>

            

            <a href="https://snap-research.github.io/GTR/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.05649" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Pre-print</span>
                
              </div>
              
                <img src="publications/images/moa.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>MoA : Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</strong>
     
            <p>
              Kuan-Chieh (Jackson) Wang, Daniil Ostashev, Yuwei Fang, Sergey Tulyakov, Kfir Aberman
            </p>

            

            <a href="https://snap-research.github.io/mixture-of-attention/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2404.11565" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ECCV</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/tc4d-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>TC4D: Trajectory-Conditioned Text-to-4D Generation</strong>
     
            <p>
              Sherwin Bahmani, Xian Liu, Yifan Wang, Ivan Skorokhodov, Victor Rong, Ziwei Liu, Xihui Liu, Jeong Joon Park, Sergey Tulyakov, Gordon Wetzstein, Andrea Tagliasacchi, David B. Lindell
            </p>

            
              <p><em>European Conveference on Computer Vision, ECCV’2024</em></p>

            

            <a href="https://sherwinbahmani.github.io/tc4d/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2403.17920" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ECCV</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/upfusion-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>UpFusion: Novel View Diffusion from Unposed Sparse View Observations</strong>
     
            <p>
              Bharath Raj Nagoor Kani, Hsin-Ying Lee, Sergey Tulyakov, Shubham Tulsiani
            </p>

            
              <p><em>European Conveference on Computer Vision, ECCV’2024</em></p>

            

            <a href="https://upfusion3d.github.io/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2312.06661" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ECCV</span>
                
              </div>
              
                <img src="publications/images/myvlm.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>MyVLM: Personalizing VLMs for User-Specific Queries</strong>
     
            <p>
              Yuval Alaluf, Elad Richardson, Sergey Tulyakov, Kfir Aberman, Daniel Cohen-Or
            </p>

            
              <p><em>European Conveference on Computer Vision, ECCV’2024</em></p>

            

            <a href="https://popspaper.github.io/pOps/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2403.14599" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/panda-70m.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</strong>
     
            <p>
              Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, Byung Eun Jeon, Yuwei Fang, Hsin-Ying Lee, Jian Ren, Ming-Hsuan Yang, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://snap-research.github.io/Panda-70M/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2402.19479" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
                  <span>Highlight</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/snap-video.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Snap Video: Scaled Spatiotemporal Transformers for Text-to-video Synthesis</strong>
     
            <p>
              Willi Menapace, Aliaksandr Siarohin, Ivan Skorokhodov, Ekaterina Deyneka, Tsai-Shien Chen, Anil Kag, Yuwei Fang, Aleksei Stoliar, Elisa Ricci, Jian Ren, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em>. <strong>Highlight</strong></p>

            

            <a href="https://snap-research.github.io/snapvideo/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2402.14797" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/4dfy-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>4D-fy: Text-to-4d Generation using Hybrid Score Distillation Sampling</strong>
     
            <p>
              Sherwin Bahmani, Ivan Skorokhodov, Victor Rong, Gordon Wetzstein, Leonidas Guibas, Peter Wonka, Sergey Tulyakov, Jeong Joon Park, Andrea Tagliasacchi, David B Lindell
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://sherwinbahmani.github.io/4dfy/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2311.17984" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
                  <span>Highlight</span>
                
              </div>
              
                <img src="publications/images/scene-tex.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors</strong>
     
            <p>
              Dave Zhenyu Chen, Haoxuan Li, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nießner
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em>. <strong>Highlight</strong></p>

            

            <a href="https://daveredrum.github.io/SceneTex/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2311.17261" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/scenewiz.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Towards Text-guided 3D Scene Composition</strong>
     
            <p>
              Qihang Zhang, Chaoyang Wang, Aliaksandr Siarohin, Peiye Zhuang, Yinghao Xu, Ceyuan Yang, Dahua Lin, Bolei Zhou, Sergey Tulyakov, Hsin-Ying Lee
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://zqh0253.github.io/SceneWiz3D/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2312.08885" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <img src="publications/images/textcraftor.jpeg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>TextCraftor: Your Text Encoder Can Be Image Guality Controller</strong>
     
            <p>
              Yanyu Li, Xian Liu, Anil Kag, Ju Hu, Yerlan Idelbayev, Dhritiman Sagar, Yanzhi Wang, Sergey Tulyakov, Jian Ren
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://snap-research.github.io/textcraftor/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2403.18978" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <img src="publications/images/hpdm.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Hierarchical Patch Diffusion Models for High-Resolution Video Generation</strong>
     
            <p>
              Ivan Skorokhodov, Willi Menapace, Aliaksandr Siarohin, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://snap-research.github.io/hpdm/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2406.07792" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <img src="publications/images/spad.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>SPAD: Spatially Aware Multi-View Diffusers</strong>
     
            <p>
              Yash Kant, Aliaksandr Siarohin, Ziyi Wu, Michael Vasilkovsky, Guocheng Qian, Jian Ren, Riza Alp Guler, Bernard Ghanem, Sergey Tulyakov, Igor Gilitschenski
            </p>

            
              <p><em>Computer Vision and Patter Recognition, CVPR’2024</em></p>

            

            <a href="https://yashkant.github.io/spad/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2402.05235" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>Transactions on Grahpics</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/pgm-2.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Promptable Game Models: Text-guided Game Simulation via Masked Diffusion Models</strong>
     
            <p>
              Willi Menapace, Aliaksandr Siarohin, Stéphane Lathuilière, Panos Achlioptas, Vladislav Golyanik, Sergey Tulyakov, Elisa Ricci
            </p>

            
              <p><em>Transactions on Grahpics, TOG’2024</em></p>

            

            <a href="https://snap-research.github.io/promptable-game-models/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://dl.acm.org/doi/full/10.1145/3635705" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICLR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/magic-123-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Promptable Game Models: Text-guided Game Simulation via Masked Diffusion Models</strong>
     
            <p>
              Guocheng Qian, Jinjie Mai, Abdullah Hamdi, Jian Ren, Aliaksandr Siarohin, Bing Li, Hsin-Ying Lee, Ivan Skorokhodov, Peter Wonka, Sergey Tulyakov, Bernard Ghanem
            </p>

            
              <p><em>International Conference on Learning Representations, ICLR’2024</em></p>

            

            <a href="https://guochengqian.github.io/project/magic123/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2306.17843" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICLR</span>
                
              </div>
              
                <img src="publications/images/hyperhuman.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion</strong>
     
            <p>
              Xian Liu, Jian Ren, Aliaksandr Siarohin, Ivan Skorokhodov, Yanyu Li, Dahua Lin, Xihui Liu, Ziwei Liu, Sergey Tulyakov
            </p>

            
              <p><em>International Conference on Learning Representations, ICLR’2024</em></p>

            

            <a href="https://snap-research.github.io/HyperHuman/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2310.08579" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>SIGGRAPH Asia</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/cinemagraphs-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Text-Guided Synthesis of Eulerian Cinemagraphs</strong>
     
            <p>
              Aniruddha Mahapatra, Aliaksandr Siarohin, Hsin-Ying Lee, Sergey Tulyakov, Jun-Yan Zhu
            </p>

            
              <p><em>Transactions on Graphics, SIGGRAPH Asia’2023</em></p>

            

            <a href="https://text2cinemagraph.github.io/website/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2307.03190" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>NeurIPS - World's fastest mobile diffusion!</span>
                
              </div>
              
                <img src="publications/images/snapfusion.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>SnapFusion: Text-to-image Giffusion Model on Mobile Devices within Two Seconds</strong>
     
            <p>
              Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun Fu, Yanzhi Wang, Sergey Tulyakov, Jian Ren
            </p>

            
              <p><em>Neural Information Processing Systems, NeurIPS’2023</em></p>

            

            <a href="https://snap-research.github.io/SnapFusion/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2306.00980" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>NeurIPS</span>
                
              </div>
              
                <img src="publications/images/vader.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Autodecoding latent 3d diffusion models</strong>
     
            <p>
              Evangelos Ntavelis, Aliaksandr Siarohin, Kyle Olszewski, Chaoyang Wang, Luc Van Gool, Sergey Tulyakov
            </p>

            
              <p><em>Neural Information Processing Systems, NeurIPS’2023</em></p>

            

            <a href="https://snap-research.github.io/3DVADER/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2307.05445" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICCV</span>
                
              </div>
              
                <img src="publications/images/eformerv2.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Rethinking Vision Transformers for MobileNet Size and Speed</strong>
     
            <p>
              Yanyu Li, Ju Hu, Yang Wen, Georgios Evangelidis, Kamyar Salahi, Yanzhi Wang, Sergey Tulyakov, Jian Ren
            </p>

            
              <p><em>International Conference on Computer Vision, ICCV’2023</em></p>

            

            <a href="https://github.com/snap-research/EfficientFormer" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2206.01191" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICCV</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/text-to-tex.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Text2Tex: Text-driven Texture Synthesis via Diffusion Models</strong>
     
            <p>
              Dave Zhenyu Chen, Yawar Siddiqui, Hsin-Ying Lee, Sergey Tulyakov, Matthias Nießner
            </p>

            
              <p><em>International Conference on Computer Vision, ICCV’2023</em></p>

            

            <a href="https://daveredrum.github.io/Text2Tex/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2303.11396" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICCV</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/infinicity.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>InfiniCity: Infinite-Scale City Synthesis</strong>
     
            <p>
              Chieh Hubert Lin, Hsin-Ying Lee, Willi Menapace, Menglei Chai, Aliaksandr Siarohin, Ming-Hsuan Yang, Sergey Tulyakov
            </p>

            
              <p><em>International Conference on Computer Vision, ICCV’2023</em></p>

            

            <a href="https://hubert0527.github.io/infinicity/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2301.09637" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/uva.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Unsupervised Volumetric Animation</strong>
     
            <p>
              Aliaksandr Siarohin, Willi Menapace, Ivan Skorokhodov, Kyle Olszewski, Jian Ren, Hsin-Ying Lee, Menglei Chai, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em></p>

            

            <a href="https://snap-research.github.io/unsupervised-volumetric-animation/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2301.11326" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <img src="publications/images/affection.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Affection: Learning Affective Explanations for Real-World Visual Data</strong>
     
            <p>
              Panos Achlioptas, Maks Ovsjanikov, Leonidas Guibas, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em></p>

            

            <a href="https://affective-explanations.org/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2210.01946" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/mobile-r2l-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Real-Time Neural Light Field on Mobile Devices</strong>
     
            <p>
              Junli Cao, Huan Wang, Pavlo Chemerys, Vladislav Shakhrai, Ju Hu, Yun Fu, Denys Makoviichuk, Sergey Tulyakov, Jian Ren
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em></p>

            

            <a href="https://snap-research.github.io/MobileR2L" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2301.02700" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/3davatargan.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>3DAvatarGAN: Bridging Domains for Personalized Editable Avatars</strong>
     
            <p>
              Rameen Abdal, Hsin-Ying Lee, Peihao Zhu, Menglei Chai, Aliaksandr Siarohin, Peter Wonka, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em></p>

            

            <a href="https://rameenabdal.github.io/3DAvatarGAN/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2301.02700" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/sdfusion.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation</strong>
     
            <p>
              Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alex Schwing, Liangyan Gui
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em></p>

            

            <a href="https://yccyenchicheng.github.io/SDFusion/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2212.04493" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR Highlight</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/discoscene.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis</strong>
     
            <p>
              Yinghao Xu, Menglei Chai, Zifan Shi, Sida Peng, Ivan Skorokhodov, Aliaksandr Siarohin, Ceyuan Yang, Yujun Shen, Hsin-Ying Lee, Bolei Zhou, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2023</em>. <strong>Highlight</strong></p>

            

            <a href="https://snap-research.github.io/discoscene/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2212.11984" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICLR Oral</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/3dgp-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>3D Generation on ImageNet</strong>
     
            <p>
              Ivan Skorokhodov, Aliaksandr Siarohin, Yinghao Xu, Jian Ren, Hsin-Ying Lee, Peter Wonka, Sergey Tulyakov
            </p>

            
              <p><em>International Conference on Learning Representations, ICLR’2023</em>. <strong>Oral</strong></p>

            

            <a href="https://snap-research.github.io/3dgp/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2303.01416" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICLR</span>
                
              </div>
              
                <img src="publications/images/cdcd.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation</strong>
     
            <p>
              Ye Zhu, Yu Wu, Kyle Olszewski, Jian Ren, Sergey Tulyakov, Yan Yan
            </p>

            
              <p><em>International Conference on Learning Representations, ICLR’2023</em></p>

            

            <a href="https://l-yezhu.github.io/CDCD/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2206.10535" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>NeurIPS</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/epigraph.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>EpiGRAF: Rethinking Training of 3D GANs</strong>
     
            <p>
              Ivan Skorokhodov, Sergey Tulyakov, Yiqun Wang, Peter Wonka
            </p>

            
              <p><em>Neural Information Processing Systems, NeurIPS’2022</em></p>

            

            <a href="https://universome.github.io/epigraf" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2206.10535" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>NeurIPS</span>
                
              </div>
              
                <img src="publications/images/efficient-former.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>EfficientFormer: Vision Transformers at MobileNet Speed</strong>
     
            <p>
              Yanyu Li, Geng Yuan, Yang Wen, Eric Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren
            </p>

            
              <p><em>Neural Information Processing Systems, NeurIPS’2022</em></p>

            

            <a href="https://github.com/snap-research/EfficientFormer" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2206.01191" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ECCV</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/r2l.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis</strong>
     
            <p>
              Huan Wang, Jian Ren, Zeng Huang, Menglei Chai, Kyle Olszewski, Yun Fu, Sergey Tulyakov
            </p>

            
              <p><em>European Conference on Computer Vision, ECCV’2022</em></p>

            

            <a href="https://snap-research.github.io/R2L/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2203.17261" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>SIGGRAPH</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/neroic-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>NeROIC: Neural Rendering of Objects from Online Image Collections</strong>
     
            <p>
              Zhengfei Kuang, Kyle Olszewski, Menglei Chai, Zeng Huang, Panos Achlioptas, Sergey Tulyakov
            </p>

            
              <p><em>Transactions on Graphics, SIGGRAPH’2022</em></p>

            

            <a href="https://zfkuang.github.io/NeROIC/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2201.02533" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/pe-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Playable Environments: Video Manipulation in Space and Time</strong>
     
            <p>
              Willi Menapace, Stéphane Lathuilière, Aliaksandr Siarohin, Christian Theobalt, Sergey Tulyakov, Vladislav Golyanik, Elisa Ricci
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2022</em></p>

            

            <a href="https://willi-menapace.github.io/playable-environments-website/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2203.01914" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/mmvid-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning</strong>
     
            <p>
              Ligong Han, Jian Ren, Hsin-Ying Lee, Francesco Barbieri, Kyle Olszewski, Shervin Minaee, Dimitris Metaxas, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2022</em></p>

            

            <a href="https://snap-research.github.io/MMVID/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2203.02573" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/stylegan-v-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2</strong>
     
            <p>
              Ivan Skorokhodov, Sergey Tulyakov, Mohamed Elhoseiny
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2022</em></p>

            

            <a href="https://universome.github.io/stylegan-v" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2112.14683" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/mraa.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Motion Representations for Articulated Animation</strong>
     
            <p>
              Aliaksandr Siarohin, Oliver Woodford, Jian Ren, Menglei Chai, Sergey Tulyakov
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2021</em></p>

            

            <a href="https://snap-research.github.io/articulated-animation/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2104.11280" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR Oral</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/pvg-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Playable Video Generation</strong>
     
            <p>
              Willi Menapace, Stéphane Lathuilière, Sergey Tulyakov, Aliaksandr Siarohin, Elisa Ricci
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2021</em>. <strong>Oral</strong></p>

            

            <a href="https://willi-menapace.github.io/playable-video-generation-website/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2101.12195" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>ICLR Spotlight</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/mocogan-hd-1.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>A Good Image Generator Is What You Need for High-Resolution Video Synthesis</strong>
     
            <p>
              Yu Tian, Jian Ren, Menglei Chai, Kyle Olszewski, Xi Peng, Dimitris N. Metaxas, Sergey Tulyakov
            </p>

            
              <p><em>International Conference on Learning Representations, ICLR’2021</em>. <strong>Spotlight</strong></p>

            

            <a href="https://bluer555.github.io/MoCoGAN-HD/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2104.15069" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>NeurIPS</span>
                
              </div>
              
                <video class="rounded img-fluid img-max" loop autoplay muted>
                  <source src="publications/images/fomm.mp4" type="video/mp4">
                </video>
              
            </div>

          </div>

          <div class="col py-3">
            <strong>First Order Motion Model for Image Animation</strong>
     
            <p>
              Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, Nicu Sebe
            </p>

            
              <p><em>Neural Information Processing Systems, NeurIPS’2019</em></p>

            

            <a href="https://aliaksandrsiarohin.github.io/first-order-model-website/" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/2003.00196" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR</span>
                
              </div>
              
                <img src="publications/images/mocogan.png" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>MoCoGAN: Decomposing Motion and Content for Video Generation</strong>
     
            <p>
              Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2018</em></p>

            

            <a href="https://github.com/sergeytulyakov/mocogan" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://arxiv.org/abs/1707.04993" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      <hr class="d-md-none"/><div class="row py-3">
          <div class="col-sm-3 py-3">
            <div class="item">
              <div class="notify-badge badge text-bg-primary">
                <span>CVPR Oral</span>
                
              </div>
              
                <img src="publications/images/samc.jpg" class="rounded img-fluid img-max" />
              
            </div>

          </div>

          <div class="col py-3">
            <strong>Self-Adaptive Matrix Completion for Heart Rate Estimation from Face Videos under Realistic Conditions</strong>
     
            <p>
              Sergey Tulyakov, Xavier Alameda Pineda, Elisa Ricci, Jijun Yin, Jeffrey Cohn, Nicu Sebe
            </p>

            
              <p><em>Computer Vision and Pattern Recognition, CVPR’2016</em>. <strong>Oral</strong></p>

            

            <a href="https://stulyakov.com/papers/cvpr2016.html" type="button" class="btn btn-primary btn-sm">Project</a>
            <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Tulyakov_Self-Adaptive_Matrix_Completion_CVPR_2016_paper.pdf" type="button" class="btn btn-primary btn-sm">Paper</a>
          </div>
        </div>
      
    </div>

  </div>

  </main>
  <script src="../assets/dist/js/bootstrap.bundle.min.js"></script>

</body>

</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <title>Sergey Tulyakov</title>
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet"/>
    <link href="css/bootstrap-social.css" rel="stylesheet"/>
    <link href="css/custom.css" rel="stylesheet"/>
    <!-- Custom CSS -->
    <link href="css/modern-business.css" rel="stylesheet"/>
    <!-- Custom Fonts -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script>

    <script src="https://www.googletagmanager.com/gtag/js?id=UA-115492969-1"></script>
    <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-115492969-1');

    </script>
</head>
<body>
<!-- Page Content -->
<div class="container">
    <!-- Marketing Icons Section -->
    <div class="row">
        <div class="col-md-4 col-sm-4">
            <img class="img-responsive img-rounded" src="images/sergey.jpg" alt=""/>
        </div>
        <div class="col-md-8 col-sm-8">
            <h1 class="page-header first-header">Sergey Tulyakov</h1>
            <p>
                Welcome! I am a Lead Research Scientist heading the Creative Vision team at Snap Research. My work
                focuses on creating methods for manipulating the world via computer vision and machine learning. This
                includes style transfer, photorealistic object manipulation and animation, video synthesis, prediction
                and retargeting. My work has been published as 20+ top conference papers, journals and patents resulting
                in multiple tech transfers, including Snapchat Pet Tracking and Real-time Neural Lenses (gender swap,
                baby face).
            </p>

            <p> Before joining Snap Inc., I built the real-time face tracking and reconstruction engine behind <a
                    href="https://www.facebook.com/facify/videos/426807287711138/">facify.me</a>. 2016, I was a research
                intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/">Microsoft
                    Research</a>, Cambridge, UK, and worked with <a href="http://www.nowozin.net/sebastian/">Sebastian
                    Nowozin</a> and <a href="https://www.microsoft.com/en-us/research/people/awf/">Andrew Fitzgibbon</a>
                on improving generative models.
                In 2017, I interned at NVIDIA with <a href="http://mingyuliu.net/">Ming-Yu Liu</a>, <a
                        href="http://xiaodongyang.org/">Xiaodong Yang</a> and <a href="http://jankautz.com/">Jan
                    Kautz</a> and worked on video generation. </p>

            <p>I am a PhD graduate from the University of Trento, Italy, where I worked with <a
                    href="http://disi.unitn.it/~sebe/">Nicu Sebe</a> at the Multimedia and Human Understanding Group
                <a href="http://mhug.disi.unitn.it/">MHUG</a>. Before joining the MHUG group, I worked as a software
                engineer for six years.</p>

            <p>I am looking for prospective interns and collaborators. If you are interested send me an email.</p>
            <p>Media coverage:</p>
            <ul>
                <li>Pet Tracking: <a href="https://www.thesun.co.uk/tech/7478208/snapchat-cat-filters-how-to-lenses/">The
                    Sun</a>, <a
                        href="https://www.theverge.com/2018/12/26/18156183/snapchat-dog-lenses-filter-christmas">The
                    Verge</a>, <a
                        href="https://variety.com/2019/digital/news/secret-life-of-pets-2-snapchat-ar-lens-cat-dog-1203154288/">Variety</a>,
                    <a href="https://www.cnet.com/news/snapchat-unleashes-lenses-for-your-pup/">CNet</a> and others
                </li>
                <li>Real-time Neural Lenses: <a
                        href="https://www.cnet.com/how-to/want-to-try-that-gender-face-swap-thing-everyones-doing-heres-how/">CNet</a>,
                    <a href="https://www.theverge.com/2019/6/11/18661623/snapchat-gender-swap-filter-police-underage-hookup">BoredPanda</a>,
                    <a href="https://www.theverge.com/2019/6/11/18661623/snapchat-gender-swap-filter-police-underage-hookup">Newsweek</a>,
                    <a href="https://www.telegraph.co.uk/technology/2019/07/23/baby-face-gender-swap-filters-propel-snapchat-strongest-growth/">The
                        Telegraph</a> and others
                </li>
            </ul>
            <p>Contact:
                <a href="mailto:stulyakov@snap.com">stulyakov@snap.com</a></p>
            <br/>
            <a class="btn btn-social-icon btn-facebook" href="https://www.facebook.com/s.tulyakov"><i
                    class="fa fa-facebook"></i></a>
            <a class="btn btn-social-icon btn-github" href="https://github.com/sergeytulyakov"><i
                    class="fa fa-github"></i></a>
            <a class="btn btn-social-icon btn-linkedin" href="https://www.linkedin.com/in/sergeytulyakov"><i
                    class="fa fa-linkedin"></i></a>
            <a class="btn btn-info" href="data/Sergey_Tulyakov_CV.pdf">Download CV</a></div>
        <div class="col-lg-12">
            <h3 class="page-header">Research</h3>
        </div>
        <div class="col-md-12">
            <p>The ultimate goal of the Creative Vision group is to develop cutting edge computer vision, machine
                learning, and graphics technology to unlock creativity of users and creators in a variety of products at
                Snap. Our work enables machines to see, understand and manipulate the world. We focus on the following
                broad directions:
            <ul>
                <li><b>Understanding Humans:</b> Human digitization (segmentation, 3D pose and geometry of face, body,
                    hand, clothes)
                </li>
                <li><b>Understanding the World:</b> Digitization of the world and objects in it (recognition,
                    segmentation, 3D reconstruction, scene understanding)
                </li>
                <li><b>Tools for Creativity:</b> Arbitrary AR manipulation of the world, including style transfer for
                    shape and texture of faces, objects and scenes, adding and removing objects from the scene
                </li>
                <li><b>Efficient Algorithms and Architectures:</b> Technologies for faster, smaller models and more
                    accurate inference
                </li>
            </ul>
            We are hiring! Feel free to reach out to me if you are interested to know more or apply <a
                href="https://wd1.myworkdaysite.com/recruiting/snapchat/snap/job/Los-Angeles-California/Research-Scientist_R0009063">here</a>.

        </div>
    </div>

    <div class="row">
        <div class="col-lg-12">
            <h3 class="page-header">Work Experience</h3>
            <div class="col-md-3">
                <p>Jul 2017 - Present:</p>
            </div>
            <div class="col-md-8">
                <p>Lead Research Scientist at SNAP Research, Venice, CA</p>
            </div>
            <div class="col-md-3">
                <p>Jan 2017 - Apr 2017:</p>
            </div>
            <div class="col-md-8">
                <p>Research Intern at NVIDIA Research, Santa Clara, CA</p>
            </div>
            <div class="col-md-3">
                <p>Aug 2016 - Nov 2016:</p>
            </div>
            <div class="col-md-8">
                <p>Research Intern at Microsoft Research, Cambridge, UK</p>
            </div>
            <div class="col-md-3">
                <p>July 2010 - Sept 2012:</p>
            </div>
            <div class="col-md-8">
                <p> Team and Project Lead at HiQo-Solutions, Minsk, Belarus </p>
            </div>
        </div>
        <div class="col-md-12">
            <div class="col-md-3">
                <p>June 2006 - June 2010:</p>
            </div>
            <div class="col-md-8">
                <p>Software Engineer at Todes Ltd, Minsk, Belarus </p>
            </div>
        </div>
    </div>

    <div class="row">
        <div class="col-lg-12">
            <h3 class="page-header">Education</h3>
            <div class="col-md-3">
                <p>Nov 2012 - Apr 2017:</p>
            </div>
            <div class="col-md-8">
                <p>PhD Canditate at The Univesity of Trento, Italy</p>
            </div>
        </div>
        <div class="col-md-12">
            <div class="col-md-3">
                <p>Sept 2014 - Feb 2015:</p>
            </div>
            <div class="col-md-8">
                <p>Research intern at the Robotics Institute, Carnegie-Mellon University</p>
            </div>
        </div>
        <div class="col-md-12">
            <div class="col-md-3">
                <p>Sept 2009 - July 2010:</p>
            </div>
            <div class="col-md-8">
                <p>MSc at the Belarusian State University of Intormatics and Radioelectronics</p>
            </div>
        </div>
        <div class="col-md-12">
            <div class="col-md-3">
                <p>Sept 2004 - July 2009:</p>
            </div>
            <div class="col-md-8">
                <p>B.Eng at the Belarusian State University of Intormatics and Radioelectronics</p>
            </div>
        </div>
    </div>

<!--    <div class="row">-->
<!--        <div class="col-lg-12">-->
<!--            <h2 class="page-header">Personal Projects</h2>-->


<!--            <div class="row">-->
<!--                <div class="col-md-12 col-lg-12">-->
<!--                    <h3>Facify.me</h3>-->
<!--                    <p><a href="http://facify.me">Facify.me</a> is an augmented reality technology, based on 3D face-->
<!--                        tracking & reconstruction. It features more than 100 fps 3D tracking on an iPhone 5. It tracks-->
<!--                        804 3D face points.-->
<!--                        The app is avilable on <a href="https://itunes.apple.com/app/id1116628712">App Store</a>. I am-->
<!--                        planning to release the tracking code soon. Stay tuned!</p>-->

<!--                    <div class="col-md-8 col-sm-12 col-lg-8">-->
<!--                        &lt;!&ndash; <div class="embed-responsive"> &ndash;&gt;-->
<!--                        <iframe src="https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2Ffacify%2Fvideos%2F281380238920511%2F&width=300&show_text=false&height=536&appId"-->
<!--                                width="300" height="536" style="border:none;overflow:hidden" scrolling="no"-->
<!--                                frameborder="0" allowTransparency="true" allowFullScreen="true"></iframe>-->
<!--                        &lt;!&ndash; </div> &ndash;&gt;-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class="col-md-12 col-lg-12">-->
<!--                    <h3>FaceCept3D</h3>-->
<!--                    <p><a href="https://github.com/sergeytulyakov/FaceCept3D">FaceCept3D</a> is a flexible <strong>open-source-->
<!--                        technology</strong> for 3D face analysis and recognition, available on GitHub. It allows for-->
<!--                        head pose estimation and facial expression recognition from extreme head poses. Key advantages-->
<!--                        of the technology include: flexible architecture that decouples scientific algorithms from-->
<!--                        technical components and real-time processing pipeline.</p>-->
<!--                    <div class="col-md-8 col-sm-12 col-lg-8">-->
<!--                        <div class="embed-responsive embed-responsive-16by9">-->
<!--                            <iframe width="854" height="480" src="https://www.youtube.com/embed/oU2c5H1p4yk"-->
<!--                                    frameborder="0" allowfullscreen></iframe>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->

<!--                <div class="col-md-12 col-lg-12">-->
<!--                    <h3>FaceCept</h3>-->
<!--                    <p>FaceCept technology is a set of components that allows real-time analysis of people's faces. It-->
<!--                        includes gender, age, facial expression, new/returning and attention time recognition. The-->
<!--                        technology is cross-platform: it works even in a browser. The project took first place in ITJUMP-->
<!--                        2012.</p>-->

<!--                    <div class="col-md-6 col-sm-12 col-lg-8">-->
<!--                        <div class="embed-responsive embed-responsive-16by9">-->
<!--                            <iframe width="854" height="480" src="https://www.youtube.com/embed/n5kveMTHDVo"-->
<!--                                    frameborder="0" allowfullscreen></iframe>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->

<!--            </div>-->
<!--        </div>-->
<!--    </div>-->

    <div class="row">
        <div class="col-lg-12">
            <h3 class="page-header">Teaching</h3>
        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Teaching Computers to Imagine with Deep Generative Models</p>
                </strong></p>
                <p>Sergey Tulyakov, Stéphane Lathuilière</p>
                <p>University of Trento, Italy. November 19-26, 2019</p>
                <a href="teaching/teaching-to-imagine.html" class="btn btn-info">Course material</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-lg-12">
            <h3 class="page-header">Publications</h3>

        </div>
    </div>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/tbn.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>[Oral] Transformable Bottleneck Networks</p>
                </strong></p>
                <p>Kyle Olszewski, Sergey Tulyakov, Oliver Woodford, Hao Li, Linjie Luo</p>
                <p><em>International Conference on Computer Vision, 2019</em></p>
                <a href="https://arxiv.org/abs/1904.06458" class="btn btn-info">Paper</a>
                <a href="https://github.com/kyleolsz/TB-Networks" class="btn btn-info">Code</a>
                <a href="https://kyleolsz.github.io/TB-Networks/" class="btn btn-info">Project</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/laplace.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Laplace Landmark Localization</p>
                </strong></p>
                <p>Joseph P Robinson, Yuncheng Li, Ning Zhang, Yun Fu, and Sergey Tulyakov</p>
                <p><em>International Conference on Computer Vision, 2019</em></p>
                <a href="https://arxiv.org/abs/1903.11633" class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>


    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/monkey-net.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>[Oral] Animating arbitrary objects via deep motion transfer</p>
                </strong></p>
                <p>Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci, Nicu Sebe</p>
                <p><em>Computer Vision and Pattern Recognition, 2019</em></p>
                <a href="https://arxiv.org/abs/1812.08861" class="btn btn-info">Paper</a>
                <a href="https://github.com/AliaksandrSiarohin/monkey-net" class="btn btn-info">Code</a>
                <a href="http://www.stulyakov.com/papers/monkey-net.html" class="btn btn-info">Project</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/3d-guided.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>3D Guided Fine-Grained Face Manipulation</p>
                </strong></p>
                <p>Zhenglin Geng, Chen Cao, Sergey Tulyakov</p>
                <p><em>Computer Vision and Pattern Recognition, 2019</em></p>
                <a href="https://arxiv.org/abs/1902.08900" class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>

 <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/expressive.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Real-Time Patch-Based Stylization of Portraits Using Generative Adversarial Network</p>
                </strong></p>
                <p>David Futschik, Menglei Chai, Chen Cao, Chongyang Ma, Aleksei Stoliar, Sergey Korolev, Sergey Tulyakov, Michal Kučera, and Daniel Sýkora</p>
                <p><em>ACM/EG Expressive Symposium, 2019</em></p>
                <a href="https://dcgi.fel.cvut.cz/home/sykorad/Futschik19-NPAR.pdf" class="btn btn-info">Paper</a>
                <a href="https://dcgi.fel.cvut.cz/home/sykorad/facestyleGAN.html" class="btn btn-info">Project</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/train-one.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Train One Get One Free: Partially Supervised Neural Network for Bug Report Duplicate Detection and Clustering</p>
                </strong></p>
                <p>Lahari Poddar, Leonardo Neves, William Brendel, Luis Marujo, Sergey Tulyakov, Pradeep Karuturi</p>
                <p><em>North American Chapter of the Association for Computational Linguistics, 2019</em></p>
                <a href="https://arxiv.org/abs/1903.12431" class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>


    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/mocogan.png" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>MoCoGAN: Decomposing Motion and Content for Video Generation</p>
                </strong></p>
                <p>Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz</p>
                <p><em>Computer Vision and Pattern Recognition, 2018</em></p>
                <a href="https://arxiv.org/abs/1707.04993" class="btn btn-info">Paper</a>
                <a href="https://github.com/sergeytulyakov/mocogan" class="btn btn-info">Code</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/pami-wei.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Recurrent Convoltutional Shape Regression</p>
                </strong></p>
                <p>Wei Wang, Sergey Tulyakov and Nicu Sebe </p>
                <p><em>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018</em></p>
                <a href="data/recurrent-convolutional-shape.pdf"
                   class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/hybrid-vae.png" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Hybrid VAE: Improving Deep Generative Models using Partial Observations</p>
                </strong></p>
                <p>Sergey Tulyakov, Andrew Fitzgibbon, Sebastian Nowozin</p>
                <p><em>Neural Information Processing Systems Workshops, 2017</em></p>
                <a href="https://arxiv.org/abs/1711.11566" class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/pami.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>Viewpoint-consistent 3D Face Alignment</p>
                </strong></p>
                <p>Sergey Tulyakov, Laszlo A. Jeni, Jeffrey F. Cohn and Nicu Sebe </p>
                <p><em>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017</em></p>
                <a href="data/viewpoint-consistent-3d-face-alignment.pdf"
                   class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/accv-2016.png" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                <p>[Oral] Recurrent Convolutional Face Alignment</p>
                </strong></p>
                <p>Wei Wang, Sergey Tulyakov and Nicu Sebe </p>
                <p><em>Asian Conference on Computer Vision, 2016</em></p>
                <a href="data/recurrent-convolutional-face-alignment.pdf"
                   class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/cvpr-2016.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                    <b>[Oral] </b><a href="papers/cvpr2016.html">Self-Adaptive Matrix Completion for Heart Rate
                    Estimation from Face Videos under Realistic Conditions</a>
                </strong></p>
                <p> Sergey Tulyakov, Xavier Alameda Pineda, Elisa Ricci, Jijun Yin, Jeffrey Cohn and Nicu Sebe </p>
                <p><em>Computer Vision and Pattern Recognition, 2016</em></p>
                <a href="papers/cvpr2016.html" class="btn btn-info">Read more</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/coming-soon.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                    <a href="papers/iccv2015.html">Regressing a 3D Face Shape from a Single Image</a>
                </strong></p>
                <p> Sergey Tulyakov and Nicu Sebe </p>
                <p><em>International Conference on Computer Vision, 2015</em></p>
                <a href="papers/iccv2015.html" class="btn btn-info">Read more</a>
            </div>
        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/facecept3d.png" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                    FaceCept3D: Real Time 3D Face Tracking and Analysis
                </strong></p>
                <p> Sergey Tulyakov, Radu Vieriu, Enver Sangineto and Nicu Sebe </p>
                <p><em>International Conference on Computer Vision Workshops, 2015</em></p>
                <a href="data/FaceCept3D.%20Real%20Time%203D%20Face%20Tracking%20and%20Analysis.pdf"
                   class="btn btn-info">Paper
                </a>
            </div>

        </div>
    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/fg-2015.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">

            <div>
                <p><strong>
                    Facial Expression Recognition under a Wide Range of Head Poses
                </strong></p>
                <p> Radu Vieriu, Sergey Tulyakov, Stas Semeniuta, Enver Sangineto and Nicu Sebe</p>

                <p><em>Automatic Face and Gesture Recognition, 2015</em></p>

                <a href="https://github.com/sergeytulyakov/FaceCept3D" class="btn btn-info">Code</a>
                <a href="https://github.com/sergeytulyakov/FaceCept3D/raw/master/papers/Facial%20Expression%20Recognition%20under%20a%20Wide%20Range%20of%20Head%20Poses.pdf"
                   class="btn btn-info">Paper</a>
            </div>
        </div>
    </div>
    <div class="row">

    </div>
    <hr/>

    <div class="row">
        <div class="col-md-3 col-sm-3">
            <img class="img-responsive " src="images/icpr-2014.jpg" alt=""/>
        </div>

        <div class="col-md-8 col-sm-8">
            <div>
                <p><strong>
                    Robust Real-Time Extreme Head Pose Estimation
                </strong></p>
                <p> Sergey Tulyakov, Radu Vieriu, Stas Semeniuta and Nicu Sebe</p>

                <p><em>International Conference on Pattern Recognition, 2014</em></p>

                <a href="https://github.com/sergeytulyakov/FaceCept3D" class="btn btn-info">Code</a>
                <a href="#" class="btn btn-info">Data</a>
                <a href="https://github.com/sergeytulyakov/FaceCept3D/raw/master/papers/Robust%20Real-Time%20Extreme%20Head%20Pose%20Estimation.pdf"
                   class="btn btn-info">Paper</a>

            </div>
        </div>
    </div>

    <!-- Footer -->
    <hr>
    <footer>
        <div class="row">
            <div class="col-lg-12">
                <p>Sergey Tulyakov, October 2019</p>
            </div>
        </div>
    </footer>

</div>

</body>


</html>

